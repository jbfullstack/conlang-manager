import { NextRequest, NextResponse } from 'next/server';
import { openai } from '@/lib/openai';
import parseLLMJson, { buildLLMPromptRequest } from '@/lib/llm-utils';
import { prisma } from '@/lib/prisma';

function withTimeout<T>(p: Promise<T>, ms: number): Promise<T> {
  return new Promise<T>((resolve, reject) => {
      const timer = setTimeout(() => {
        reject(new Error('timeout'));
      }, ms);

    p.then((v) => {
      clearTimeout(timer);
      resolve(v);
    }).catch((e) => {
      clearTimeout(timer);
      reject(e);
    });
  });
}

export async function POST(request: NextRequest) {
  try {
    const { conceptIds } = await request.json();
    
    // üîç DEBUG 1: V√©rifier ce qui arrive du front-end
    console.log('üîç conceptIds re√ßus:', conceptIds);
    
    // R√©cup√©rer les concepts demand√©s avec leurs propri√©t√©s
    const conceptsFromDB = await prisma.concept.findMany({
      where: {
        id: { in: conceptIds },
        isActive: true
      },
      include: {
        conceptProperties: {
          include: {
            property: true
          }
        }
      }
    });

    // üîç DEBUG 2: V√©rifier ce que retourne Prisma
    console.log('üîç conceptsFromDB trouv√©s:', conceptsFromDB.length);
    console.log('üîç Premier concept de DB:', conceptsFromDB[0]);

    // Transformer pour l'analyse
    const concepts = conceptsFromDB.map(c => ({
      id: c.id,
      mot: c.mot,
      concept: c.definition,
      type: c.type,
      proprietes: c.conceptProperties.map(cp => cp.property.name)
    }));

    // üîç DEBUG 3: V√©rifier la transformation
    console.log('üîç concepts transform√©s:', concepts);
    
    const prompt = `
    Tu es un linguiste expert en langue construite par composition de concepts primitifs.

    CONCEPTS S√âLECTIONN√âS (IDs et labels):
    ${concepts.map(c => `- ${c.id} : ${c.mot} (${c.type})`).join('\n')}

    OBJECTIF: produire la meilleure composition reliant ces concepts pour exprimer un sens donn√©.

    CONVENTIONS:
    - Pattern attendu: ["id1","id2",...]
    - Structure du sens: d√©crit par un champ "sens" et une justification
    - Si des r√®gles algorithmiques simples permettent le r√©sultat directement, privil√©gier l‚Äôalgorithme; sinon d√©l√©guer √† l‚ÄôLLM
    - R√âSULTAT EN JSON UNIQUEMENT avec les champs:
      {
        "sens": "texte du sens d√©gag√©",
        "confidence": 0.0,
        "justification": "raisonnement",
        "examples": ["exemple d‚Äôusage"],
        "alternatives": [
          {"sens": "sens alternatif", "confidence": 0.0}
        ],
        "source": "algorithmic" | "llm"
      }

    T√ÇCHE: retourne le JSON correspondant √† la composition d√©termin√©e par les concepts fournis. Si une r√®gle sp√©cifique existe (par ex. go + tomu = torrent), applique-la et renseigne le champ source = "algorithmic".
    R√âPONSE EN JSON UNIQUEMENT
    `;

    console.log('compost POST prompt :', prompt);

    const response = await withTimeout(
      openai.chat.completions.create(buildLLMPromptRequest(prompt, 0.3, 500)),
      20000 // 20s timeout
    );

    const raw = response.choices?.[0]?.message?.content ?? '{}';
    const result = parseLLMJson(raw);

    console.log('compost POST result :', result);
    return NextResponse.json({ ...result, source: 'llm' });
    
  } catch (error: any) {
    console.error('Erreur compose:', error);

    // Timeout sp√©cifique
    if (error?.message === 'timeout') {
      return NextResponse.json({
        sens: "Limite de temps IA",
        confidence: 0,
        justification: "L'appel IA n'a pas r√©pondu dans les d√©lais.",
        source: 'error',
        error_type: 'timeout'
      }, { status: 200 });
    }
    
    // GESTION SP√âCIFIQUE DES ERREURS OPENAI
    if (error?.status === 429) {
      return NextResponse.json({
        sens: "Limite de requ√™tes atteinte",
        confidence: 0,
        justification: "Trop de requ√™tes envoy√©es √† l'IA. R√©essayez dans quelques minutes.",
        source: 'error',
        error_type: 'rate_limit'
      }, { status: 200 }); // 200 pour que l'UI affiche le message
    }
    
    if (error?.status === 401) {
      return NextResponse.json({
        sens: "Erreur d'authentification IA",
        confidence: 0,
        justification: "Cl√© API OpenAI invalide ou expir√©e.",
        source: 'error',
        error_type: 'auth_error'
      }, { status: 200 });
    }
    
    if (error?.status === 402) {
      return NextResponse.json({
        sens: "Cr√©dit IA √©puis√©",
        confidence: 0,
        justification: "Votre cr√©dit OpenAI est √©puis√©. Veuillez recharger votre compte.",
        source: 'error',
        error_type: 'insufficient_quota'
      }, { status: 200 });
    }
    
    // Erreur g√©n√©rale
    return NextResponse.json({
      sens: "Erreur d'analyse",
      confidence: 0,
      justification: "Erreur technique lors de l'analyse. R√©essayez plus tard.",
      source: 'error',
      error_type: 'general_error'
    }, { status: 200 });
  }
}

// R√àGLES ALGORITHMIQUES
// function applyCompositionRules(concepts: any[]) {
//   const elements = concepts.filter(c => c.type === 'element');
//   const actions = concepts.filter(c => c.type === 'action');
  
//   if (elements.length === 1 && actions.length === 1) {
//     const element = elements[0];
//     const action = actions[0];
    
//     // Cas sp√©ciaux
//     if (element.mot === 'go' && action.mot === 'tomu') {
//       return {
//         sens: 'torrent/cascade',
//         confidence: 0.9,
//         justification: 'Combinaison valid√©e: eau + mouvement rapide = flux naturel',
//         source: 'algorithmic',
//         examples: ['Le torrent d√©vale la montagne']
//       };
//     }
    
//     return {
//       sens: `${element.concept} ${action.concept}`,
//       confidence: 0.6,
//       justification: `R√®gle: √©l√©ment + action = processus`,
//       source: 'algorithmic'
//     };
//   }
  
//   return null;
// }